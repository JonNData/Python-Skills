{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Guide to Neural Networks.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonNData/Python-Skills/blob/master/Guide_to_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5iE1YZZhl2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# AFTER HOURS PRACTICE\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTZE6vh1hwWb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = {'x1': [1,1,0,0],\n",
        "        'x2': [0,1,0,1],\n",
        "        'y': [0,0,1,1]}\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RGyZqcMh8Nx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create perceptron class\n",
        "\n",
        "class Perceptron:\n",
        "  \"\"\" Base perceptron class\"\"\"\n",
        "\n",
        "  def __init__(self, n_iter=100):\n",
        "    self.n_iter = n_iter\n",
        "\n",
        "  def __sigmoid(self, x):\n",
        "    return 1/ (1+np.exp(-x))\n",
        "\n",
        "  def __sigmoid_derivative(self, x):\n",
        "    fx = self.__sigmoid(x)\n",
        "    return fx * (1 - fx)\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\" fit class and do iterations\"\"\"\n",
        "    np.random.seed(42)\n",
        "    # random for number of columns in X , then 1 row for \n",
        "    self.weights = 2 * np.random.random((X.shape[1], 1)) - 1\n",
        "\n",
        "    for i in range(self.n_iter):\n",
        "      # now do the same process as whiteboard\n",
        "      # Feed forward\n",
        "      weighted_sum = np.dot(X, self.weights)\n",
        "      activated_output = self.__sigmoid(weighted_sum)\n",
        "\n",
        "      # Backpropagation\n",
        "      # actual - predicted\n",
        "      error = np.array(df[['y']]) - activated_output\n",
        "      # adjust by the error * the derivative (chain rule of sigmoid(activated out))\n",
        "      adjustments = error * self.__sigmoid_derivative(weighted_sum)\n",
        "      # New weights\n",
        "      self.weights = self.weights + np.dot(X.T, adjustments)\n",
        "\n",
        "  def predict(self, X):\n",
        "      # Feed forward on something new\n",
        "      weighted_sum = np.dot(X, self.weights)\n",
        "      activated_output = self.__sigmoid(weighted_sum)\n",
        "      return activated_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOePvF95kyj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate the class we just made\n",
        "model = Perceptron()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6AQVccMk8r-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ac994dba-2dcf-4b56-d079-bcfa9428b168"
      },
      "source": [
        "X = df[['x1','x2']].values\n",
        "y = df['y'].values\n",
        "X, y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[1, 0],\n",
              "        [1, 1],\n",
              "        [0, 0],\n",
              "        [0, 1]]), array([0, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZXkDjncldsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ivm3_ikLlanS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "984c382e-1d4b-4b4c-e43c-d693194a63d9"
      },
      "source": [
        "model.weights"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.9091744 ],\n",
              "       [ 1.82203941]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc4SvR-BnUaf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c730e7d7-08bc-4ef3-d55d-98cbcba7a683"
      },
      "source": [
        "model.predict(np.array([[1,1]]))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11035353]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2kb6yICpiT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(np.array([[1,1], [1,0], [0,1], [0,0]]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okubLWaSrxP9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "7de2cdeb-cf14-4b1a-9563-2ba4921fc7fb"
      },
      "source": [
        "[1 if x >= 0.5 for x in y_pred]"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-85-d93bd6fcedf2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    [1 if x >= 0.5 for x in y_pred]\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgdkYLrKs_iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUwgzSiOtAsf",
        "colab_type": "text"
      },
      "source": [
        "Now for a multi-layered one\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uOtf7QftAAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create  multi layered\n",
        "\n",
        "class BasicNN:\n",
        "  \"\"\" Base perceptron class\"\"\"\n",
        "\n",
        "  def __init__(self, inputs=8, hidden=4, output=1, n_iter=100):\n",
        "    self.inputs = inputs\n",
        "    self.hidden_nodes = hidden\n",
        "    self.output_nodes = output\n",
        "    self.n_iter = n_iter\n",
        "\n",
        "    self.weights1 = 2 * np.random.random((self.inputs, self.hidden_nodes)) - 1\n",
        "    self.weights2 = 2 * np.random.random((self.hidden_nodes, self.output_nodes)) - 1\n",
        "\n",
        "  def __sigmoid(self, x):\n",
        "    return 1/ (1+np.exp(-x))\n",
        "\n",
        "  def __sigmoid_derivative(self, x):\n",
        "    fx = self.__sigmoid(x)\n",
        "    return fx * (1 - fx)\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    \"\"\" fit class and do iterations\"\"\"\n",
        "    np.random.seed(42)\n",
        "    # random for number of columns in X , then 1 row for \n",
        "    self.weights = 2 * np.random.random((X.shape[1], 1)) - 1\n",
        "\n",
        "    for i in range(self.n_iter):\n",
        "      \n",
        "      # From input to hidden layer\n",
        "      weighted_sum = np.dot(X, self.weights1)\n",
        "      activated_hidden_output = self.__sigmoid(weighted_sum)\n",
        "\n",
        "      # from hidden to output\n",
        "      weighted_sum2 = np.dot(activated_hidden_output, self.weights2)  \n",
        "      activated_output = self.__sigmoid(weighted_sum2)\n",
        "\n",
        "      # Backpropagation\n",
        "\n",
        "      # first from output to hidden layer\n",
        "      # actual - predicted\n",
        "      out_hidden_error = np.array(df[['y']]) - activated_output\n",
        "      # adjust by the error * the derivative (chain rule of sigmoid(weighted sum 2))\n",
        "      out_hidden_adjustments = out_hidden_error * self.__sigmoid_derivative(weighted_sum2)\n",
        "\n",
        "      # Now from hidden layer to inputs\n",
        "      hidden_input_error = np.dot(out_hidden_adjustments, self.weights2.T)\n",
        "      hidden_input_adjustments = hidden_input_error * self.__sigmoid_derivative(weighted_sum)\n",
        "\n",
        "      # New weights\n",
        "      self.weights1 = self.weights1 + np.dot(X.T, hidden_input_adjustments)\n",
        "      self.weights2 = self.weights2 + np.dot(activated_hidden_output.T, out_hidden_adjustments)\n",
        "\n",
        "      \n",
        "  def predict(self, X):\n",
        "      # Feed forward on something new\n",
        "      weighted_sum = np.dot(X, self.weights1)\n",
        "      activated_hidden = self.__sigmoid(weighted_sum)\n",
        "      weighted_sum2 = np.dot(activated_hidden, self.weights2)\n",
        "      activated_output = self.__sigmoid(weighted_sum2)\n",
        "      return activated_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dbRTsQrydQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = BasicNN(inputs=2, hidden=4, output=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCnxUvo8yuZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.fit(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fFLSWoJy4wZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "7d8677bd-2edf-47ee-bcc5-6ffae7d0ff37"
      },
      "source": [
        "y_pred2 = model2.predict(np.array([[1,1], [1,0], [0,1], [0,0]]))\n",
        "y_pred2"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12049529],\n",
              "       [0.0909757 ],\n",
              "       [0.93177395],\n",
              "       [0.84700515]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oaQg9JZzIh5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "diabetes = pd.read_csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IshvvdJQz1gi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = list(diabetes)[:-1]\n",
        "target = 'Outcome'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDaSSx-3z8_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(diabetes[features])\n",
        "y = diabetes[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PdkacjC0Mcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test,y_train, y_test = train_test_split(X_scaled, y, test_size=0.25,\n",
        "                                                    random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yPEdL490hlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Basic perceptron\n",
        "model = Perceptron()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = [1 if x >= 0.5 else 0 for x in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOtxJwfK07hg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# multi layer\n",
        "model_2 = BasicNN(inputs=8, hidden=8, output=1, n_iter=1000)\n",
        "model_2.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model_2.predict(X_test)\n",
        "y_pred = [1 if x>=0.5 else 0 for x in y_pred]\n",
        "\n",
        "accuracy = accuracy_score(y_pred, y_test)\n",
        "accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPyroZFShfbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Neural Networks are a class of machine learning algorithms that are loosely inspired by neurons in the\n",
        "#human brain. \n",
        "\n",
        "#NN are a mathematical function that maps a given input to the desired output:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2xV9c4GhfbQ",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG8dGbqPhfbR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A perceptron is simply a mathematical function that takes in a set of inputs, performs some \n",
        "#mathematical computation, and outputs the results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzA8YBzPhfbU",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO06eiP6hfbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Wi refers to the weights of the perceptron "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZAsLBJHhfbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Recurrent neural networks (RNNs) predict time series data - are used in areas such as speech recognition\n",
        "#generative afversarial network(GAN) - pits 2 NN against each other - generates photoraelistic images\n",
        "#that are indistinguishable to the human eye. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAuWxA4Nhfbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The basic architecture of neural networks:\n",
        "\n",
        "#Neural networks consist of the following components:\n",
        "\n",
        "#1 - an input layer, x\n",
        "#2 - an arbitrary amount of hidden layers \n",
        "#3 - a set of weights and biases between each layer, W and b\n",
        "#4 - a choice of activation fucntion for each hidden layer, σ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDX0N9Dihfbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#diagram shows the architecture of a two layer NN - **note that the input layer is typically excluded\n",
        "#when counting layers**"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qve-Dvm4hfbi",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fk7dLXiNhfbj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training a Neural Network:\n",
        "\n",
        "#create a NeuralNetwork class:\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y):\n",
        "        self.input = x\n",
        "        self.weights1 = np.random.rand(self.input.shapre[1], 4)\n",
        "        self.weights2 = np.random.rand(4,1)\n",
        "        self.y = y\n",
        "        self.output = np.zeros(self.y.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5opXx8Shfbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the putput of ŷ of a simple 2 layer neural network is :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaMMTqRehfbp",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n_v0eGBhfbq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the right values for the weights and biases determine the strength of the predictions\n",
        "\n",
        "#The process of fine tuning the weights and biases from the input data is known as training the \n",
        "#neural network\n",
        "\n",
        "#each iteration of the training process consists of the following steps:\n",
        "#1 - calculation the predicted output ŷ, known as feedforward\n",
        "#2 - updating the weights and biases, known as backpropagation \n",
        "\n",
        "#the graph illustrates this process:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2woUmWuhfbt",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdNSJv-ghfbu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Feedforward:\n",
        "\n",
        "#feedforward is just simple calculus - add a feedforward function to the python code : "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD0cfSqMhfbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0 / (1 + np.exp(-x))\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y):\n",
        "        self.input = x\n",
        "        self.weights1 = np.random.rand(self.input.shapre[1], 4)\n",
        "        self.weights2 = np.random.rand(4,1)\n",
        "        self.y = y\n",
        "        self.output = np.zeros(self.y.shape)\n",
        "        \n",
        "    def feedforward(self):\n",
        "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
        "        self.output = sigmoid(np.dot(self,.layer1, self.weights2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qH6Xj5yrhfb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The Loss Function:\n",
        "\n",
        "#There are many loss functions and the nature of the problem will dictate the choice of loss fucntion\n",
        "\n",
        "#The sum-of-squares error is the sum of the difference between each predicted value and the actual\n",
        "#value. The difference is squared so that we measure the absolute value of the difference :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SHlXOtrhfb4",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9OovhKchfb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Backpropagation:\n",
        "\n",
        "#once you ahve measured the error of the prediction(loss) you need to propagate the error back, and\n",
        "#update the weights and biases.\n",
        "\n",
        "#in order to know the amount to adjust the weights and biases by, you need to know the derivative of\n",
        "#the loss function with respect to the weights and biases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TZG9ZBthfb7",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tO7zLfLhfb8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#updating the weights and biases by increasing/decreasing by the derivative is called Gradient descent\n",
        "\n",
        "#you can directly calculate the derivative of the loss function with respect to the weights and \n",
        "#biases because the equation of the loss function does not contain the weights and biases the chain \n",
        "#rule will help calculate this. However Keras takes care of gradient descent for you without having\n",
        "#to work out the chain rule from scratch \n",
        "\n",
        "##all you need to know is that once you have the derivative(slope) of the loss function with respect to\n",
        "#the weights you can adjust the weights accordingly:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVbYZo6zhfb-",
        "colab_type": "code",
        "colab": {},
        "outputId": "7b2d09f6-8a08-46c9-eb8c-89356b2d6c5e"
      },
      "source": [
        "#add the backporp function to the code:\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1.0/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1.0 - x)\n",
        "\n",
        "class NeuralNetwork:\n",
        "    def __init__(self, x, y):\n",
        "        self.input    = x\n",
        "        self.weights1 = np.random.rand(self.input.shape[1],4) \n",
        "        self.weights2 = np.random.rand(4,1) \n",
        "        self.y        = y\n",
        "        self.output = np.zeros(self.y.shape)\n",
        "\n",
        "    def feedforward(self):\n",
        "        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n",
        "        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n",
        "\n",
        "    def backprop(self):\n",
        "        # application of the chain rule to find the derivation of the \n",
        "        # loss function with respect to weights2 and weights1\n",
        "        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) *                                                                          \n",
        "                     sigmoid_derivative(self.output)))       \n",
        "        d_weights1 = np.dot(self.input.T, (np.dot(2*(self.y - self.output) \n",
        "                    * sigmoid_derivative(self.output), self.weights2.T) *                                                \n",
        "                      sigmoid_derivative(self.layer1))) \n",
        "\n",
        "        self.weights1 += d_weights1\n",
        "        self.weights2 += d_weights2\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X = np.array([[0,0,1],\n",
        "                  [0,1,1],\n",
        "                  [1,0,1],\n",
        "                  [1,1,1]])\n",
        "    y = np.array([[0],[1],[1],[0]])\n",
        "    nn = NeuralNetwork(X,y)\n",
        "\n",
        "    for i in range(1500):\n",
        "        nn.feedforward()\n",
        "        nn.backprop()\n",
        "\n",
        "    print(nn.output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01767503]\n",
            " [0.97399606]\n",
            " [0.98404971]\n",
            " [0.02379462]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJV-gLruhfcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#looking at the predictions vs. actual - the model algortihm trained the NN successfully and the \n",
        "#predications converged on the true values \n",
        "\n",
        "#predication ----actual \n",
        "#0.023             0\n",
        "#0.984             1\n",
        "#0.976             1\n",
        "#0.020             0\n",
        "\n",
        "#the slight difference between the predication and the actual values is desirable - it prevents \n",
        "#overfitting and allows the NN to generalize better to unseen data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZxPRejYhfcF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deep Learning and Neural Networks:\n",
        "\n",
        "#deep learning is a machine learning algorithm that uses multiple layers in a NN for learning(deep nets)\n",
        "#while a single layer perceptron is the simplest neural network - deep nets are NN on the opposite end\n",
        "#of that complexity spectrum \n",
        "\n",
        "#Deep Neural Network (DNN) each layer learns information of increasing complexity before passing it to\n",
        "#successive layers. for example a DNN trained on facial recognition  the first few layers learn to \n",
        "#identify edges in faces, followed by contours such as eyes and evenutally complete facial features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1P8N5X9hfcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TensorFLow and Keras - deep learning libraries\n",
        "\n",
        "#TensorFLow is a library for NN and deep learning that is one of the most popular today\n",
        "\n",
        "#Keras is a high level API that runs on top of TensorFlow that removes the complexities in building\n",
        "#NN and enables rapid experimentation and testing without concerning the user with low level \n",
        "#implemenatation detials.  Provides a simple and intutive API for building NN using TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fs_Jt8z2hfcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The Fundamental Building Blocks in Keras:\n",
        "\n",
        "#layers - you can stack layers linearly to create a model\n",
        "\n",
        "#The Loss Function that you choose will provide the metrics for which you will use to train the model \n",
        "#using an optimizer. \n",
        "\n",
        "#these are fundamental building blocks in Keras because you can build any NN using these basic structures\n",
        "\n",
        "#the diagram illustrates the relationship between these building blocks in Keras:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khEzQ5fyhfcP",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huVDp3TchfcP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#you can think of layers in Keras as an atom, they are the smallest unit in the NN. Each\n",
        "#layer takes in an input performs a mathematical function, then outputs that for the next layer\n",
        "#the core layers in Keras includes dense layers, activation layers, and dropout layers, pooling\n",
        "#layers, convolutional layers \n",
        "\n",
        "#a dense layer implements the following:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW2cUisBhfcS",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMBlYe8RhfcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#y is the ouput O is the activation function X is the input and W and b are the weights and \n",
        "#biases"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrjIgiYLhfcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if layers can be thought of as atoms, then models can be through of as molecules in Keras\n",
        "\n",
        "#a model is a collection of layers, the most commonly used in Keras is the Sequential model. \n",
        "\n",
        "#a Sequential model allows you to linearly stack layers on one another, where a single layer is\n",
        "#connected to one other layer only. Allowing you to easily desgin model architectures without\n",
        "#worrying about the underlying math involved. \n",
        "\n",
        "# After defining the model architecture - you need to define the training process, which is \n",
        "#done using the compile method in Keras.\n",
        "\n",
        "#the compile method takes in several arguments, but the most important that need to be defined\n",
        "#are the optimizer and loss function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJ_pT9IDhfcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loss Function - error metric for NN training \n",
        "\n",
        "#There are several loss functions implemented in Keras, the most commonly used are :\n",
        "#mean_squared_error\n",
        "#categorical_crossentropy\n",
        "#binary_crossentropy\n",
        "\n",
        "#as a general rule of thumb you should choose which loss function to use based on:\n",
        "\n",
        "#1 - mean_squared_error --- if the problem is a regression problem \n",
        "#2 - categorical_crossentropy --- if the problem is a multiclass classification problem \n",
        "#3 - binary_crossentropy --- if the problem is a binary classification problem "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcqHgARlhfcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Optimizers - Training algorithm for NN\n",
        "\n",
        "#An optimizer is an algorithm for updating the weights of the NN in the training process. \n",
        "#Optimizers in Keras are based on the gradient descent algorithm\n",
        "#your choice in optimizer should depend on the nature of the problem. in general: the \n",
        "#Adam optimmizer works best for DNNs while the sgd optimizer works best for shallow NN\n",
        "#The Adagrad optimizer is also a popular choice and it adaprts the learning rate of the \n",
        "#alogirhtm based on how frequent a paerticular set of weights are updated this elliminates\n",
        "#the need to manually tune the learning rate hyperparameter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSxCOaZ0hfce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The major advantage of Keras is that you do not have to worry about the low level implementation \n",
        "# details and math while building the NN. All you do in Keras is call a series of APIs to build the\n",
        "# NN allowing you to focus on the high level details enabling rapid experimentation. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEwCdZg7hfcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting the data train/test/val:\n",
        "\n",
        "#1 - training set : the NN will be trained on this subset of the data\n",
        "#2 - Validation set: this set of data allows us to perform hyperparameter tuning using an unbiased \n",
        "        #source of the data\n",
        "#3- Testing set: the final evaluation of the NN will be based on this subset of the data\n",
        "\n",
        "#the purpose of splitting the data is to avoid overfitting and to provide an unbiased source of data\n",
        "#for evaluation model performance. \n",
        "\n",
        "#The testing set is also known as the hold out dataset - as the NN will never be trained using it\n",
        "\n",
        "#General rule of thumb is to split 80% training 20% testing and then to split the training into \n",
        "#80% training and 20% validiation again: \n",
        "\n",
        "#splitting must be done randomly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUltM7-5hfci",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smsiCkgAhfcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#MLP is a class of feedforward NN that has at least one hidden layer, with each layer activated by a\n",
        "#non liner activation function. This multilayer NN and non linear activation allows MLPs to produce\n",
        "#non linear decision boundaries - which is crucial in multi dimensional real world datasets "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6O9btvihfcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model architecture of the MLP:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8niPQYihfco",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUq8RpBYhfco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#input layer:\n",
        "\n",
        "#each node in the input layer refers to each feature (column) in the dataset - since there are 8 \n",
        "#there should be 8 nodes in the input layer of the MLP \n",
        "\n",
        "#hidden layer - takes the input layer and applies non linear activation function to it \n",
        "\n",
        "#activation function - transformers in NN that take an input value, transform it and pass it to the \n",
        "#next level -- rectified linear unit (ReLU) and sigmoid are activiation functions \n",
        "\n",
        "#ReLU - always used as the activation function for intermediate hidden layers (non output layer) \n",
        "#has been proven to be superior to all previoulsy used activation functions for DNNs\n",
        "\n",
        "#What the ReLU does is to simply consider only the non-negative portion of the original X, and to treat\n",
        "#the negative portion as 0 \n",
        "\n",
        "#the graph illustrates this:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uncO7hPwhfcr",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0SA634yhfcr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sigmoid activation function:\n",
        "\n",
        "#makes a prediction (for output layer) on the class of the label. \n",
        "\n",
        "#ideal for binary classification problems \n",
        "\n",
        "#takes a value and squashes it between 0 and 1: "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaAIDiL6hfcu",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHpjAE8-hfcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#if the transformed value (f(x)) is greater than 0.5 it will classify as class 1 -- if the transformed\n",
        "#value is less tha 0.5 it will classify as 0 \n",
        "\n",
        "#The sigmoid activation function allows you to take an input value and outputs a binary class(1 or 0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCwAnsCUhfcx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Building : \n",
        "\n",
        "#The Sequential class in Keras constructs a NN like Legos, stacking layers on top of one another\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#add first hidden layer:\n",
        "from keras.layers import Dense\n",
        "# Add the first hidden layer\n",
        "model.add(Dense(32, activation='relu', input_dim=8))\n",
        "\n",
        "#add second hidden layer\n",
        "# Add the second hidden layer\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "#add output layer\n",
        "# Add the output layer\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3RHhqyjhfcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Compilation:\n",
        "\n",
        "#before training the model, you need to define the parameters of the training process, which is done\n",
        "#via the compile method \n",
        "\n",
        "#there are 3 different parameters to define for the training process:\n",
        "#1 - Optimizer \n",
        "#2 - Loss Function \n",
        "#3- metrics\n",
        "\n",
        "#then run the compile function :\n",
        "#compile the model:\n",
        "model.compile(optimizer = 'adam',\n",
        "             loss = 'binary_crossentropy',\n",
        "             metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXs2AuaThfc1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model Training :\n",
        "#to train the MLP model call fit function - \n",
        "\n",
        "#train the model for 200 epochs\n",
        "model.fit(X_train, y_train, epochs=200)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ4-AFBghfc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the loss decreases and the accuracy increases over each epoch,as the learning algorithm continuously\n",
        "#updates the weights and biases in the MLP according to the training data. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNx_1v9Vhfc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Results Analysis:\n",
        "\n",
        "#next - evaluate the model based on the testing accuracy- confusion matrix - and receiver operating \n",
        "#charactersitic (ROC) curve:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGpPQVnNhfc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#evaluate the results : \n",
        "#evaluate -\n",
        "\n",
        "scores = model.evaluate(X_train, y_train)\n",
        "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1] * 100))\n",
        "\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDya-a5hhfdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the difference isnt surprising since the model was trained on the training set. \n",
        "\n",
        "#the testing accuracy should always be used to evaluate the real-wrold performance as the testing set\n",
        "#represents real world data that the model has never seen before"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3x7ViNfhfdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Confusion Matrix :\n",
        "\n",
        "#useful visualization tool that provides analysis on the true negative, false positive, false negative\n",
        "#and true positives made by the model \n",
        "\n",
        "#you should also look at the confusion matrix to understand the performance of the model\n",
        "\n",
        "# The definition of true negative, false positive, false negative, and true positives are as follows:\n",
        "\n",
        "# True negative: Actual class is negative , and the model predicted negative \n",
        "# False positive: Actual class is negative , but the model predicted positive \n",
        "# False negative: Actual class is positive , but the model predicted negative \n",
        "# True positive: Actual class is positive, and the model predicted positive \n",
        "\n",
        "#you clearly will want the false neg and pos numbers to be as low as possible and the true neg and pos\n",
        "#numbers to be as high as possible \n",
        "\n",
        "#you construct the matrix using confusion_matrix class from sklearn using seaborn :\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_test_pred = model.predict_classes(X_test)\n",
        "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
        "ax = sns.heatmap(c_matrix, annot=True, \n",
        "                 xticklabels=['', ''],\n",
        "                 yticklabels=['', ''], \n",
        "                 cbar=False, cmap='Blues')\n",
        "ax.set_xlabel(\"Prediction\")\n",
        "ax.set_ylabel(\"Actual\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHpMIgNuhfdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ROC Curve  - for classification tasks its best to also look at ROC curve to evaluate the model\n",
        "#the ROC curve is a plot with the True Positive rate (TPR) on the y axis and the False Positive \n",
        "#Rate(FPR) on the x axis \n",
        "\n",
        "#when you analysis the ROC cruve you look at the area under the curve (AUC) to evaluate the \n",
        "#performance of the model that produced the curve. A large AUC indicates that the model is able to\n",
        "#differentiate the respective classes with high accuracy, while a low AUC indicates that the model \n",
        "#makes poor, often wrong predictions.\n",
        "\n",
        "#a ROC curve that lies on the diagnoal indicates that the model does no better than random as \n",
        "#illustrated in the diagram:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sij_MdFQhfdI",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAKWCcVKhfdJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get predicted probabilites of each class:\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt \n",
        "y_test_pred_probs = model.predict(X_test) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM4dJzg6hfdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run the roc_curve to get the corresponding false positive rate and true positive \n",
        "#rate for ROC curve:\n",
        "FPR, TPR, _ = roc_curve(y_test, y_test_pred_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYpXzJKFhfdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot the values \n",
        "plt.plot(FPR, TPR)\n",
        "plt.plot([0,1],[0,1],'--', color='red') #diagonal line\n",
        "plt.title('ROC Curve')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7t3qxHdhfdQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#further improvements:\n",
        "\n",
        "#in general any limitation in performance is usually due to the lack of strong features in the dataset\n",
        "\n",
        "#one way to increase the number of features you provide to the model is via feature enginerring\n",
        "\n",
        "#feature engineering is the process of using ones domain knowledge of the problem to create new \n",
        "#features for the machine learning algorithm. \n",
        "\n",
        "#feature enginerring is one of the most important aspects of data science\n",
        "\n",
        "#you can also consider removing features to improve model performance this is known as feature\n",
        "#selection - it is used when you beleive that the original dataset contains to much noise and \n",
        "#removing the noisy feature (features that are not strong predictions) may improve model performance\n",
        "\n",
        "#one popular way to do feature selection is to use decision trees \n",
        "\n",
        "#decision trees are a seperate class of machine learning models with a tree like data structure\n",
        "\n",
        "#decision trees are useful as they calculate and rank the most important features according to \n",
        "#certain statistical criteria. \n",
        "\n",
        "# you can first fit the data using the decision tree, and then use the output from the decision tree\n",
        "#to remove features that are deemed unimportant before providing the reduced dataset to the NN. \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3gfJUFxhfdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deep feedforward network - \n",
        "\n",
        "#model architecture of the deep feedforward neural network: "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F79-IGzChfdU",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ObZpVwRhfdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#regression - predict the value of a continuous variable \n",
        "#classification - predict a class \n",
        "\n",
        "#in regression the root mean square error(RMSE) is best used as the error metric \n",
        "\n",
        "#RMSE takes the square of the difference between the predicted value and the actual value to ensure\n",
        "#over estimation and under estimations are penalized equally \n",
        "\n",
        "#the RMSE provides a loss function for the NN allowing it to tune its weights during the training \n",
        "#process in order to reduce the error of its predictions "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAnnKbiGhfdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model building using Keras\n",
        "\n",
        "#first split the DF into traing(x) and the target variable you are trying to predict(y)\n",
        "\n",
        "X = df.loc[:, df.columns != 'fare_amount']\n",
        "y = df.loc[:, 'fare_amount']\n",
        "\n",
        "#then split into training det (80/20):\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "#build Sequential model in Keras : \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, activation= 'relu', input_dim=X_train.shape[1]))\n",
        "model.add(Dense(64, activation= 'relu'))\n",
        "model.add(Dense(32, activation= 'relu'))\n",
        "model.add(Dense(8, activation= 'relu'))\n",
        "model.add(Dense(1))\n",
        "\n",
        "#verify the structure of the model:\n",
        "model.summary()\n",
        "\n",
        "#compile and train the NN on the training data:\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "model.fit(X_train, y_train, epochs=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BpzvnBmhfdY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#analyize results:\n",
        "\n",
        "#function to make a prediction using a random sample from testing set:\n",
        "def predict_random(df_prescaled, X_test, model):\n",
        "    sample = X_test.sample(n=1, random_state=np.random.randint(low=0, \n",
        "                                                              high=10000))\n",
        "    idx = sample.index[0]\n",
        "    \n",
        "    actual_fare = df_prescaled.loc[idx,'fare_amount']\n",
        "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', \n",
        "                 'Saturday', 'Sunday']\n",
        "    day_of_week = day_names[df_prescaled.loc[idx,'day_of_week']]\n",
        "    hour = df_prescaled.loc[idx,'hour']\n",
        "    predicted_fare = model.predict(sample)[0][0]\n",
        "    rmse = np.sqrt(np.square(predicted_fare-actual_fare))\n",
        "\n",
        "    print(\"Trip Details: {}, {}:00hrs\".format(day_of_week, hour))  \n",
        "    print(\"Actual fare: ${:0.2f}\".format(actual_fare))\n",
        "    print(\"Predicted fare: ${:0.2f}\".format(predicted_fare))\n",
        "    print(\"RMSE: ${:0.2f}\".format(rmse))\n",
        "    \n",
        "#pulls a random row from the testing set and feeds it to the model for prediction - then calculates\n",
        "#and displays the RMSE of the prediction - "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AOh0waihfda",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#run the function :\n",
        "predict_random(df_prescaled, X_test, model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4MIMHdZhfde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculate the RMSE for the entire training set:\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "train_pred = model.predict(X_train)\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
        "\n",
        "test_pred = model.predict(X_test)\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, test_pred))\n",
        "\n",
        "print(\"Train RMSE: {:0.2f}\".format(train_rmse))\n",
        "print(\"Test RMSE: {:0.2f}\".format(test_rmse))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n7kJNwghfdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Computer Vision and Object Recognition - Ch 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv82RNHHhfdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#computer vision is an engineering field where the objected is to create programs that can extract\n",
        "#meaning from images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPIWVCi8hfdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Types of object recognition tasks: - object recognition can be broadly classified into 3 types:\n",
        "\n",
        "#1 - Image classification\n",
        "#2 - Object detection\n",
        "#3 - Instance segmentation "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xelpUui6hfdp",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Vi2ZS5hfdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image classification - the input to the problem is an image and the required output is a \n",
        "#prediction of the class that the image belongs to - the problem is applied on pixels as the input\n",
        "#data (the intensity value of each pixel) \n",
        "\n",
        "#Object Detection - the input to the problem is an image and the required output are bounding boxes\n",
        "#surrounding the detected objects. The NN can no longer assume there is only one class present in the\n",
        "#image - it must assume that the image contains multiple classes - it must identify the presence of \n",
        "#each class in the image - adn draw a bounding box around each of them - \n",
        "\n",
        "#Instance Segmentation - the input is an image and the output are pixel groupings that correspond to\n",
        "#each class. is especially useful and prevelant in tech today - "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMN8fOY2hfdx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Digital Images as neural netowrk input:\n",
        "\n",
        "#all digital images are numerical in nature - in a pc while pixels have a value 0 and black pixels\n",
        "# have a value 255 - everything else in between have a value between 0 and 255 - making them numerical\n",
        "#data \n",
        "\n",
        "#for color images - they are 3 channels - red, green, and blue (RGB) the pixel values in each channel\n",
        "#then represent the intensity of each (red green blue) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYOrL51Ihfdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the seperation of the color image into its RGB channels - the image is stacked in a 3D manner\n",
        "#in contrast a grayscale image has only two dimensions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2qEW4Tshfd1",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsgg83zUhfd2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filtering and Convolution : \n",
        "\n",
        "#characteristic features O and X:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4Ux9DyHhfd4",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDgQQwe3hfd4",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKg9vhRJhfd4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the presence of the characteristic feature (known as the filter) in an images gives a big hint on \n",
        "#the class of the imgage - "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAJFkD6ihfd6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#filtering operation : "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFGZkov3hfd7",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxB_QTNZhfd8",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWP2OjeZhfd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the process of sliding the window through the entire image and calculating the filtered value is\n",
        "#known as convolution - the layer in the NN that performs convolution is known as the convolutional\n",
        "#layer - convolution provides a map to the areas where the characteristic feature is found in each\n",
        "#image - it ensures that the NN is able to perform intelligent, dynamic object recognition"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1D_xcZhhfd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#two main hyperparameters in a convolutional layer:\n",
        "\n",
        "#1 - Number of filters : \n",
        "#2 - Filter Size: "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFMNLaJZhfd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Max Pooling : \n",
        "\n",
        "#the objective of the max pooling layer is to reduce the number of weights after each convolution\n",
        "#layer - which reduces model complexity and avoids overfitting\n",
        "\n",
        "#the max pooling layer does this by looking at each subset of the input passed to it - throws out all\n",
        "#but the maximum values in the subset. \n",
        "\n",
        "#max pooling operations:"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cumWXm8ghfeA",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3giP5jJ6hfeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic architecture of CNNs : \n",
        "\n",
        "#CNNs are almost always stacked together in a block of convolution and pooling pattern\n",
        "\n",
        "#the activation function used for the convolution layer is usually ReLU :"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hL0xr8VhfeC",
        "colab_type": "text"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx1O_E06hfeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the final layers in a CNN will always be fully connected layers (dense layers) with a sigmoid or\n",
        "#softmax activation function. \n",
        "\n",
        "#**NOTE** sigmoid is used for binary classification and softmax is used for multiclass classifiction\n",
        "\n",
        "#the early layers of a CNN are responsible for identifying the characteristic spatial features, and\n",
        "#the fully connected layers at the end are responsilble for making predictions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqAKI7-PhfeD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Modern CNNs:\n",
        "\n",
        "#1 - LeNet\n",
        "#2 - AlexNet\n",
        "#3 - VGG16\n",
        "#4 - Inception\n",
        "#5 - ResNet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLmZn8gnhfeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#managing image data for Keras \n",
        "\n",
        "#handling large datasets can be slow to solve this  Keras provides flow_from_directory method\n",
        "#that takes as an input the path to the images and generates batches of data as output- the batches\n",
        "#of data are loaded into memory as required before model training. - it also allows you to perform\n",
        "#image preprocessing steps by passing an argument. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ArrMbIGhfeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Image Augmentation : \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}